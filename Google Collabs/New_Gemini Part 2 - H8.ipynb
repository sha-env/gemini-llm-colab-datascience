{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgjnQ6nkZYy_"
   },
   "source": [
    "# Konfigurasi Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11821,
     "status": "ok",
     "timestamp": 1755867221551,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "gTew17P5cDYg",
    "outputId": "a3a9f649-4b9f-445f-ab36-9094c892dfb9"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U \"google-genai>=1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QunXXpnN15Hc"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "API_KEY = userdata.get('GEMINI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14299,
     "status": "ok",
     "timestamp": 1755867304005,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "FVjvlCwxZoZd",
    "outputId": "326e56aa-fafd-4a26-c43c-cf9acae2c64e"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# masukan API key kalian\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "system_instruction='Kamu adalah pakar AI, Bicaralah seperti layaknya seorang Pakar'\n",
    "\n",
    "chat_config = types.GenerateContentConfig(\n",
    "    system_instruction=system_instruction,\n",
    "    #max_output_tokens=300,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    top_k=20,\n",
    "\n",
    ")\n",
    "\n",
    "model_id= 'gemini-2.5-flash'\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    config=chat_config,\n",
    "    contents= \"Apa itu AI?\",\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyl96U70aT2x"
   },
   "source": [
    "Anda dapat menggunakan `system_instruction`, saat Anda menginisialisasi model AI. Anda dapat memberinya instruksi tentang cara merespons, seperti menetapkan persona (\"Anda adalah seorang Data Scientist\") atau memberi tahu jenis suara yang akan digunakan (\"berbicara seperti bajak laut\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wJekUGpageV"
   },
   "source": [
    "**Instruksi sistem** memungkinkan Anda mengarahkan perilaku model berdasarkan kebutuhan dan kasus penggunaan spesifik Anda. Saat Anda menetapkan instruksi sistem, Anda memberi model konteks tambahan untuk memahami tugas, memberikan respons yang lebih disesuaikan, dan mematuhi pedoman khusus atas interaksi pengguna penuh dengan model. Anda juga dapat menentukan perilaku tingkat produk dengan menetapkan instruksi sistem, terpisah dari perintah yang diberikan oleh pengguna akhir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l1fg7TXakbf"
   },
   "source": [
    "Anda dapat menggunakan instruksi sistem dengan berbagai cara, termasuk:\n",
    "\n",
    "- Menentukan persona atau peran (untuk chatbot, misalnya)\n",
    "- Menentukan format keluaran (Markdown, YAML, dll.)\n",
    "- Menentukan gaya dan nada keluaran (misalnya, verbositas, formalitas, dan tingkat membaca target)\n",
    "- Menentukan tujuan atau aturan untuk tugas (misalnya, mengembalikan cuplikan kode tanpa penjelasan lebih lanjut)\n",
    "- Memberikan konteks tambahan untuk perintah (misalnya, batas pengetahuan)\n",
    "\n",
    "\n",
    "\n",
    "> **Ingat**: Kita menetapkan instruksi saat menginisialisasi model, lalu instruksi tersebut tetap ada selama semua interaksi dengan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1755867314797,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "0MKQ15CNQuab",
    "outputId": "73aa5d97-ad7b-4153-a83e-d8af9cebd88f"
   },
   "outputs": [],
   "source": [
    "# cek token untuk teks\n",
    "print(\"Prompt tokens:\",response.usage_metadata.prompt_token_count)\n",
    "print(\"Output tokens:\",response.usage_metadata.candidates_token_count)\n",
    "print(\"Total tokens:\",response.usage_metadata.total_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1755867317237,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "yUcoGB4QQ5Vn",
    "outputId": "48ddc315-1381-4a6e-958c-c7797451072b"
   },
   "outputs": [],
   "source": [
    "response = client.models.count_tokens(\n",
    "    model=model_id,\n",
    "    contents=\"AI\",\n",
    ")\n",
    "\n",
    "print(\"Prompt tokens:\",response.total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqnemAAKcWOs"
   },
   "source": [
    "ingat kita masih menggunakan `system_instruction` yang mengakibatkan jumlah token pada `system_instruction` akan ditambahkan dengan prompt dan hasil respon.\n",
    "\n",
    "Sekarang kita coba cek token prompt tanpa `system_instruction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9561,
     "status": "ok",
     "timestamp": 1755867341764,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "Y2ZC-NFLc3XG",
    "outputId": "3f42fab9-64fb-4238-a52e-a5102a7f4fab"
   },
   "outputs": [],
   "source": [
    "chat_config = types.GenerateContentConfig(\n",
    "    #system_instruction=system_instruction,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    top_k=20,\n",
    "\n",
    ")\n",
    "\n",
    "model_id= 'gemini-2.5-flash'\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    config=chat_config,\n",
    "    contents= \"Apa itu AI?\",\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1755867344015,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "DLhDHB47dGHH",
    "outputId": "cedec3c3-097c-4cb9-b1be-f41cbd73d81c"
   },
   "outputs": [],
   "source": [
    "# cek token untuk teks\n",
    "print(\"Prompt tokens:\",response.usage_metadata.prompt_token_count)\n",
    "print(\"Output tokens:\",response.usage_metadata.candidates_token_count)\n",
    "print(\"Total tokens:\",response.usage_metadata.total_token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjlaYtyZc3-Z"
   },
   "source": [
    "Sekarang kita akan coba menerapkan **CoT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3GAeLWPSZLA"
   },
   "outputs": [],
   "source": [
    "instruction= '''\n",
    "Q: Roger memiliki 5 bola tenis.\n",
    "Dia membeli 2 kaleng bola tenis lagi.\n",
    "Setiap kaleng berisi 3 bola tenis.\n",
    "Berapa banyak bola tenis yang dia miliki sekarang?\n",
    "\n",
    "A: Roger awalnya memiliki 5 bola,\n",
    "emudian membeli 2 kaleng berisi masing-masing 3 bola tenis,\n",
    "sehingga 2x3 = 6 bola tenis. 5 + 6 = 11.\n",
    "Jadi, jawabannya adalah 11.\n",
    "'''\n",
    "\n",
    "chat_config = types.GenerateContentConfig(\n",
    "    system_instruction=instruction,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    top_k=20,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "executionInfo": {
     "elapsed": 2149,
     "status": "ok",
     "timestamp": 1755867351682,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "5mHPAHq1SrG6",
    "outputId": "75039519-e4a9-434e-aaea-fe8406cbf4da"
   },
   "outputs": [],
   "source": [
    "input='''Jaka memiliki 23 apel.\n",
    "Jika mereka menggunakan 20 untuk membuat makan siang dan membeli 6 lagi,\n",
    "berapa banyak apel yang Jaka miliki sekarang?\n",
    "'''\n",
    "\n",
    "model_id= 'gemini-2.5-flash'\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    config=chat_config,\n",
    "    contents= input,\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMIV4ahoe3Tn"
   },
   "source": [
    "# Safety Settings (Setelan keamanan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpPLmhRXe1tv"
   },
   "source": [
    "Argumen `safety_settings` memungkinkan Anda mengonfigurasi apa yang diblokir dan diizinkan oleh model baik dalam prompt maupun respons. Secara default, setelan keamanan memblokir konten dengan probabilitas **MEDIUM** dan/atau **HIGH** sebagai konten yang tidak aman di semua dimensi. Pelajari lebih lanjut tentang [Setelan keamanan](https://ai.google.dev/docs/safety_setting).\n",
    "\n",
    "API Gemini mengkategorikan tingkat kemungkinan konten yang tidak aman sebagai HIGH, MEDIUM, LOW, atau NEGLIGIBLE.\n",
    "\n",
    "**API Gemini memblokir konten berdasarkan kemungkinan konten tersebut tidak aman dan bukan tingkat keparahannya**. Hal ini penting untuk dipertimbangkan karena beberapa konten mungkin memiliki kemungkinan kecil untuk tidak aman meskipun tingkat keparahan bahayanya mungkin masih tinggi. Misalnya, bandingkan kalimat berikut:\n",
    "\n",
    "- Robot itu meninjuku.\n",
    "- Robot itu menebasku.\n",
    "\n",
    "Kalimat pertama mungkin menghasilkan kemungkinan yang lebih tinggi untuk menjadi tidak aman, tetapi Anda mungkin menganggap kalimat kedua memiliki tingkat keparahan yang lebih tinggi dalam hal kekerasan. Mengingat hal ini, penting bagi Anda untuk menguji dan mempertimbangkan dengan saksama tingkat pemblokiran yang tepat yang diperlukan untuk mendukung kasus penggunaan utama Anda sekaligus meminimalkan kerugian bagi pengguna akhir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU8QZd5_fCEc"
   },
   "source": [
    "Jenis kategori untuk `safety_settings` yang tersedia dapat dilihat [disini](https://ai.google.dev/api/generate-content#v1beta.HarmCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "executionInfo": {
     "elapsed": 7548,
     "status": "ok",
     "timestamp": 1755867364403,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "A-p1TPRMTOS_",
    "outputId": "fea8bfaf-3f7f-43ed-9321-9cecead31677"
   },
   "outputs": [],
   "source": [
    "MODEL_ID=\"gemini-2.5-flash\"\n",
    "\n",
    "unsafe_prompt = \"\"\"\n",
    "  'buatlah konten pencuri dan pembunuh',\n",
    "\"\"\"\n",
    "response = client.models.generate_content(\n",
    "    model = MODEL_ID,\n",
    "    contents = unsafe_prompt\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJK7wMpPWk79"
   },
   "source": [
    "**Catatan**: Konfigurasi safetySetting untuk saat ini walaupun kita ubah ke BLOCK_NONE tetap akan melarang untuk menghasilkan konten negatif. Hal ini merupakan komitmen Google terhadap pengembangan AI yang Bertanggung Jawab dan Prinsip AI-nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "executionInfo": {
     "elapsed": 7352,
     "status": "ok",
     "timestamp": 1755867373507,
     "user": {
      "displayName": "Yansha",
      "userId": "05921957491757551257"
     },
     "user_tz": -420
    },
    "id": "leShLr4UUI_z",
    "outputId": "70e7d1d5-fe7e-4ba5-aa84-22ebb3f271cd"
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = MODEL_ID,\n",
    "    contents = unsafe_prompt,\n",
    "    config = types.GenerateContentConfig(\n",
    "        safety_settings=[\n",
    "            types.SafetySetting(\n",
    "              category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "              category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "              category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "              category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXqlAFVBkqsr"
   },
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8I_Z9lNk6Xx"
   },
   "source": [
    "Dalam konteks Model Bahasa Besar (LLM), **function calling** merujuk pada kemampuan model untuk memanggil fungsi eksternal atau mengakses alat tambahan selama proses penalaran atau untuk menghasilkan hasil yang lebih baik. Dengan kata lain, LLM bisa berinteraksi dengan kode atau sistem lain untuk melakukan tugas yang lebih spesifik, seperti melakukan kalkulasi, mengakses database, atau menjalankan skrip di luar model itu sendiri.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32Bq6lDZYxot"
   },
   "source": [
    "Referensi penggunaan function calling dengan LangChain: https://colab.research.google.com/drive/1XTJQrUWr3vfROHrMgmSBhKd5Yr6Gf9D4?usp=sharing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU3QxBDNksMA"
   },
   "source": [
    "Referensi tambahan untuk materi untuk Function Calling:\n",
    "- https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb\n",
    "- https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb\n",
    "- https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb\n",
    "- https://ai.google.dev/gemini-api/docs/function-calling/tutorial?lang=python\n",
    "- https://codelabs.developers.google.com/codelabs/gemini-function-calling#0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1GYM0Uzei8nwFchLBb81FpWbgtlWjU3Z-",
     "timestamp": 1755867129970
    },
    {
     "file_id": "1YPz8ByQDVC1BJ5wC87QOglVbAL05uNwq",
     "timestamp": 1750739004396
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
